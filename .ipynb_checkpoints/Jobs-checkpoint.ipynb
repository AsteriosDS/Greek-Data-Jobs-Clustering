{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4403ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from requests_html import HTMLSession\n",
    "import psycopg2 as pg2\n",
    "from geopy import geocoders\n",
    "from futures3 import ThreadPoolExecutor, as_completed\n",
    "import swifter\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_link = 'https://www.kariera.gr/en/jobs?title=&page=0&limit=20'\n",
    "headers = {'User-agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0'}\n",
    "r = requests.get(main_link, headers=headers)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd9e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "host = os.environ.get(\"DB_HOST\")\n",
    "port = os.environ.get(\"DB_PORT\")\n",
    "database = os.environ.get(\"DB_NAME\")\n",
    "user = os.environ.get(\"DB_USER\")\n",
    "password = os.environ.get(\"DB_PASSWORD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2992d6",
   "metadata": {},
   "source": [
    "## Main Idea\n",
    "### scrape all main_link + sub_links where sub_links=data%20analyst,data%20scientist,data%20engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061921b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_page = soup.find('li',class_='ant-pagination-next').previous_sibling.text\n",
    "max_pages = int(max_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eff259",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0538f8e",
   "metadata": {},
   "source": [
    "### working out how to turn pages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd324dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_link_list=[]\n",
    "for i in range(0,max_pages+1):\n",
    "    page_link_list.append('https://www.kariera.gr/en/jobs?title=&page={}&limit=20'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8121db",
   "metadata": {},
   "source": [
    "## getting all sub-links from all links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025944c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list=[]\n",
    "session = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde23c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(session, i):\n",
    "    return [y for y in session.get(i).html.links if '/en/jobs/' in y]\n",
    "\n",
    "link_list = []\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = []\n",
    "    for i in tqdm(page_link_list):\n",
    "        futures.append(executor.submit(get_links, session, i))\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        link_list.extend(future.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a934603",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c76032",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list=[]\n",
    "main = 'https://www.kariera.gr/'\n",
    "for i in link_list:\n",
    "    final_list.append(main + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29c323",
   "metadata": {},
   "source": [
    "# building the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_page(link):\n",
    "    unique_id = link[-5:]\n",
    "    a=''\n",
    "    r = requests.get(link, headers=headers)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    if soup.find('div',class_='h4 UGhAL2CE') is not None:\n",
    "        x = soup.find('div',class_='h4 UGhAL2CE').text\n",
    "        if ('Data Analyst' in x) | ('Data Scientist' in x) | ('Data Engineer' in x): \n",
    "            try:\n",
    "                job_title = soup.find('div',class_='h4 UGhAL2CE').text\n",
    "            except:\n",
    "                job_title = np.nan\n",
    "            try:\n",
    "                company = soup.find('a',class_='__8_RJM1pE').text\n",
    "            except:\n",
    "                company = np.nan\n",
    "            try:\n",
    "                location = soup.findAll('a',class_='V_oVSppD main-body-text')[0].text\n",
    "            except:\n",
    "                location = np.nan\n",
    "            try:\n",
    "                job_occupation = soup.findAll('a',class_='V_oVSppD main-body-text')[3].text\n",
    "            except:\n",
    "                job_occupation = np.nan\n",
    "            try:\n",
    "                level = soup.findAll('a',class_='V_oVSppD main-body-text')[1].text\n",
    "            except:\n",
    "                level = np.nan\n",
    "            try:\n",
    "                job_type = soup.findAll('a',class_='V_oVSppD main-body-text')[2].text\n",
    "            except:\n",
    "                job_type = np.nan\n",
    "            try:\n",
    "                result = soup.findAll('div',class_='__2DY4wJ3z hi8OBmAZ')\n",
    "                for i in result:\n",
    "                    a= i.get_text(strip=True,separator=' ')\n",
    "                    a = a.replace('\\u202f','').replace('\\xa0','').replace('/','')\n",
    "            except:\n",
    "                content = np.nan\n",
    "            temp = pd.DataFrame([{\n",
    "                    'job_id' : unique_id,\n",
    "                    'job_title' : job_title,\n",
    "                    'company' : company,\n",
    "                    'location': location,\n",
    "                    'job_occupation' : job_occupation,\n",
    "                    'level' : level,\n",
    "                    'job_type' : job_type,\n",
    "                    'content' : a,\n",
    "                    'date_scraped' : datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "                }])\n",
    "            return temp\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901bdb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = []\n",
    "    for link in tqdm(final_list):\n",
    "        futures.append(executor.submit(process_page, link))\n",
    "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "        temp = future.result()\n",
    "        if temp is not None:\n",
    "            df2 = pd.concat([df2, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f876eeab",
   "metadata": {},
   "source": [
    "## Connect to postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653de352",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = int(port)\n",
    "conn = pg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    dbname=database\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7654c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(cur):\n",
    "    create_table_command = (\"\"\" \n",
    "    CREATE TABLE IF NOT EXISTS jobs (\n",
    "    job_id int primary key NOT NULL,\n",
    "   job_title text NOT NULL,\n",
    "   company text,\n",
    "   location text,\n",
    "   job_occupation text,\n",
    "   level text,\n",
    "   job_type text,\n",
    "   content text,\n",
    "   date_scraped timestamp NOT NULL\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    cur.execute(create_table_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9dc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_job_exists(cur,job_id):\n",
    "    query = (\"\"\" select job_id from jobs where job_id = %s \"\"\")\n",
    "    cur.execute(query,(job_id,))\n",
    "    \n",
    "    return cur.fetchone() is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_db(cur, df):\n",
    "\n",
    "    l = []\n",
    "    for row in df.iterrows():\n",
    "        if check_if_job_exists(cur, row[1][0]):\n",
    "            pass\n",
    "        else:\n",
    "            l.append(row[1][0])\n",
    "\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b83fe",
   "metadata": {},
   "source": [
    "# Create dataframe with new jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_jobs = update_db(cur,df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_jobs = df2[df2['job_id'].apply(lambda x : x in new_jobs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dea587",
   "metadata": {},
   "source": [
    "## Push new jobs to postgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7206dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_into_table(cur,job_id, job_title, company, location, job_occupation, level,job_type, content, date_scraped):\n",
    "    insert_new_jobs = (\n",
    "        \"\"\" INSERT INTO jobs (job_id, job_title, company, location, job_occupation, level,\n",
    "           job_type, content, date_scraped)\n",
    "            VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s);\"\"\")\n",
    "\n",
    "    job_to_insert = (job_id, job_title, company, location, job_occupation, level,\n",
    "                     job_type, content, date_scraped)\n",
    "\n",
    "    cur.execute(insert_new_jobs,job_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b871be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_from_df_to_db(cur, df):\n",
    "    for i, row in df.iterrows():\n",
    "        insert_into_table(cur, row['job_id'], row['job_title'], row['company'],\n",
    "                          row['location'], row['job_occupation'], row['level'],\n",
    "                          row['job_type'], row['content'], row['date_scraped'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8434d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "push_from_df_to_db(cur, new_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f626bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc4b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88a8d7",
   "metadata": {},
   "source": [
    "# Fetch jobs table and clean duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a917c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    dbname=database\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaa3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with conn:\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM jobs\")\n",
    "\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows).rename(\n",
    "    columns={\n",
    "        0: 'job_id',\n",
    "        1: 'job_title',\n",
    "        2: 'company',\n",
    "        3: 'location',\n",
    "        4: 'job_occupation',\n",
    "        5: 'level',\n",
    "        6: 'job_type',\n",
    "        7: 'content',\n",
    "        8: 'date_scraped'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bf05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d1cfb7",
   "metadata": {},
   "source": [
    "## Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean and normalize the input data\n",
    "def fingerprint(row):\n",
    "    title = row['job_title'].lower().strip()\n",
    "    company = row['company'].lower().strip()\n",
    "    location = row['location'].lower().strip()\n",
    "    return title + '-' + company + '-' + location\n",
    "\n",
    "# create a new column 'fingerprint' and store the fingerprint values\n",
    "df['fingerprint'] = df.apply(fingerprint, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc936a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates('fingerprint',inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.drop('fingerprint',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2852e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DELETE FROM jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becdabf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "push_from_df_to_db(cur, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cde42",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34784bf5",
   "metadata": {},
   "source": [
    "# Fetch non duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47640bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM jobs\")\n",
    "\n",
    "rows = cur.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows).rename(\n",
    "    columns={\n",
    "        0: 'job_id',\n",
    "        1: 'job_title',\n",
    "        2: 'company',\n",
    "        3: 'location',\n",
    "        4: 'job_occupation',\n",
    "        5: 'level',\n",
    "        6: 'job_type',\n",
    "        7: 'content',\n",
    "        8: 'date_scraped'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7700c",
   "metadata": {},
   "source": [
    "## Cleaning company names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861753df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company'] = df['company'].apply(lambda x : x.replace('\\t','').strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a94e6",
   "metadata": {},
   "source": [
    "## Categorizing jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ecdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['categories'] = df['job_title'].apply(lambda x: 'Analytics' if 'Analyst' in x else\n",
    "                      ('Engineering' if 'Engineer' in x else 'Science'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1200c1",
   "metadata": {},
   "source": [
    "## Cleaning job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd75d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing spaces\n",
    "df['job_title'] = df['job_title'].apply(lambda x : x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7567497c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing locations from job titles\n",
    "# it assumes that always all locations will be preceded by ' - '\n",
    "def clean_city_from_job(job,city):\n",
    "    titles = []\n",
    "    for i,j in zip(job,city):\n",
    "        if j in i:\n",
    "            title = i[:-(3+len(j))]\n",
    "            titles.append(title)\n",
    "        else:\n",
    "            title = i\n",
    "            titles.append(title)\n",
    "    return pd.DataFrame(titles).rename(columns={0:'job_title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_city_from_job(df['job_title'], df['location']).merge(\n",
    "    df, left_index=True,\n",
    "    right_index=True).drop('job_title_y',\n",
    "                           axis=1).rename(columns={'job_title_x': 'job_title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1e3d3",
   "metadata": {},
   "source": [
    "## Cleaning content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72729c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(\n",
    "    lambda x: x.replace('Description', '').replace('Company', '').replace(\n",
    "        'ΠΕΡΙΓΡΑΦΗ ΘΕΣΗΣ ΕΡΓΑΣΙΑΣ', '').replace('Job', '').replace(\n",
    "            '’s', '').replace('Purpose', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(lambda x : re.sub(r'Requisition ID: \\d+', '', x).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7bd89",
   "metadata": {},
   "source": [
    "## Geolocate locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gn = geocoders.GeoNames('asterios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['geo'] = df['location'].swifter.apply(lambda x : gn.geocode(x)).apply(lambda loc: tuple(loc.point) if loc else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['latitude', 'longitude', 'altitude']] = pd.DataFrame(df['geo'].tolist(), index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e48d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ce115f",
   "metadata": {},
   "source": [
    "### At this point we are done with the cleaning next up is droping unwanted columns and exporting  the csv for the main app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['job_id','job_occupation','date_scraped','geo','altitude'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9670775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('job_board.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
